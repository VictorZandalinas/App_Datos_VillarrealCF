{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5643fb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# OPTA API - EXTRACTOR MA2, MA3 Y MA12 (CON SELECCI√ìN DE TEMPORADA)\n",
    "# Modificado para incluir selecci√≥n de stage/temporada\n",
    "# ====================================\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1db335c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# DICCIONARIO DE EVENT TYPES\n",
    "# ====================================\n",
    "EVENT_TYPE_MAPPING = {\n",
    "    1: \"Pass\",\n",
    "    2: \"Offside Pass\", \n",
    "    3: \"Take On\",\n",
    "    4: \"Foul\",\n",
    "    5: \"Out\",\n",
    "    6: \"Corner Awarded\",\n",
    "    7: \"Tackle\",\n",
    "    8: \"Interception\",\n",
    "    10: \"Save\",\n",
    "    11: \"Claim\",\n",
    "    12: \"Clearance\",\n",
    "    13: \"Miss\",\n",
    "    14: \"Post\",\n",
    "    15: \"Attempt Saved\",\n",
    "    16: \"Goal\",\n",
    "    17: \"Card\",\n",
    "    18: \"Player off\",\n",
    "    19: \"Player on\",\n",
    "    20: \"Player retired\",\n",
    "    21: \"Player returns\",\n",
    "    22: \"Player becomes goalkeeper\",\n",
    "    23: \"Goalkeeper becomes player\",\n",
    "    24: \"Condition change\",\n",
    "    25: \"Official change\",\n",
    "    27: \"Start delay\",\n",
    "    28: \"End delay\",\n",
    "    29: \"Temporary stop\",\n",
    "    30: \"End\",\n",
    "    32: \"Start\",\n",
    "    34: \"Team set up\",\n",
    "    36: \"Player changed Jersey number\",\n",
    "    37: \"Collection End\",\n",
    "    38: \"Temp Goal\",\n",
    "    39: \"Temp Attempt\",\n",
    "    40: \"Formation change\",\n",
    "    41: \"Punch\",\n",
    "    42: \"Good skill\",\n",
    "    43: \"Deleted event\",\n",
    "    44: \"Aerial\",\n",
    "    45: \"Challenge\",\n",
    "    47: \"Rescinded card\",\n",
    "    49: \"Ball recovery\",\n",
    "    50: \"Dispossessed\",\n",
    "    51: \"Error\",\n",
    "    52: \"Keeper pick-up\",\n",
    "    53: \"Cross not claimed\",\n",
    "    54: \"Smother\",\n",
    "    55: \"Offside provoked\",\n",
    "    56: \"Shield ball opp\",\n",
    "    57: \"Foul throw-in\",\n",
    "    58: \"Penalty faced\",\n",
    "    59: \"Keeper Sweeper\",\n",
    "    60: \"Chance missed\",\n",
    "    61: \"Ball touch\",\n",
    "    63: \"Temp Save\",\n",
    "    64: \"Resume\",\n",
    "    65: \"Contentious referee decision\",\n",
    "    67: \"50/50\",\n",
    "    68: \"Referee Drop Ball\",\n",
    "    69: \"Failed to Block\",\n",
    "    70: \"Injury Time Announcement\",\n",
    "    71: \"Coach Setup\",\n",
    "    72: \"Caught Offside\",\n",
    "    73: \"Other Ball Contact\",\n",
    "    74: \"Blocked Pass\",\n",
    "    75: \"Delayed start\",\n",
    "    76: \"Early end\",\n",
    "    79: \"Coverage interruption\",\n",
    "    80: \"Drop of Ball\",\n",
    "    81: \"Obstacle\",\n",
    "    82: \"Control\",\n",
    "    83: \"Attempted tackle\",\n",
    "    84: \"Deleted After Review\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cb94284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# CONFIGURACI√ìN\n",
    "# ====================================\n",
    "\n",
    "outletApiKey = '10lthl3y5chwn1m0fa4mfg3bqy'\n",
    "secretKey = '1u3x3eovxa0vh1lwmutbygq8xn'\n",
    "delay_seconds = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2d38a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# FUNCIONES CORE\n",
    "# ====================================\n",
    "\n",
    "def requestHeaders():\n",
    "    \"\"\"Funci√≥n OAuth id√©ntica a la notebook que funciona\"\"\"\n",
    "    timestamp = int(round(time.time() * 1000))\n",
    "    \n",
    "    post_url = f'https://oauth.performgroup.com/oauth/token/{outletApiKey}?_fmt=json&_rt=b'\n",
    "    \n",
    "    # generate a unique hash\n",
    "    key = str.encode(outletApiKey + str(timestamp) + secretKey)\n",
    "    unique_hash = hashlib.sha512(key).hexdigest()\n",
    "    \n",
    "    # call the OAuth API (post)\n",
    "    oauthHeaders = {\n",
    "        'Content-Type': 'application/x-www-form-urlencoded',\n",
    "        'Authorization': f'Basic {unique_hash}',\n",
    "        'Timestamp': str(timestamp)\n",
    "    }\n",
    "    \n",
    "    BODY = {\n",
    "        'grant_type': 'client_credentials',\n",
    "        'scope': 'b2b-feeds-auth'\n",
    "    }\n",
    "    \n",
    "    response = requests.post(post_url, data=BODY, headers=oauthHeaders)\n",
    "    access_token = response.json()['access_token']\n",
    "    oauthHeaders = {'Authorization': f'Bearer {access_token}'}\n",
    "    return oauthHeaders\n",
    "\n",
    "def get_available_stages_method1():\n",
    "    \"\"\"M√©todo 1: Usar Tournament Calendar b√°sico (sin filtros) y filtrar despu√©s\"\"\"\n",
    "    requestParameters = {\n",
    "        \"_fmt\": \"json\",\n",
    "        \"_pgSz\": \"100\",\n",
    "        \"_pgNm\": \"1\",\n",
    "        \"_rt\": \"b\"\n",
    "    }\n",
    "    \n",
    "    sdapi_get_url = f'https://api.performfeeds.com/soccerdata/tournamentcalendar/{outletApiKey}/'\n",
    "    \n",
    "    try:\n",
    "        print(\"   üîÑ Intentando con Tournament Calendar b√°sico...\")\n",
    "        response = requests.get(sdapi_get_url, headers=requestHeaders(), params=requestParameters)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        stages = {}\n",
    "        tournament_calendars = data.get('tournamentCalendar', [])\n",
    "        \n",
    "        for tc in tournament_calendars:\n",
    "            stage = tc.get('stage', {})\n",
    "            competition = tc.get('competition', {})\n",
    "            stage_id = stage.get('id')\n",
    "            stage_name = stage.get('name', 'N/A')\n",
    "            comp_name = competition.get('name', 'N/A')\n",
    "            comp_id = competition.get('id', 'N/A')\n",
    "            \n",
    "            if stage_id and stage_id not in stages:\n",
    "                stages[stage_id] = {\n",
    "                    'name': stage_name,\n",
    "                    'competition': comp_name,\n",
    "                    'competition_id': comp_id,\n",
    "                    'start_date': stage.get('startDate', 'N/A'),\n",
    "                    'end_date': stage.get('endDate', 'N/A')\n",
    "                }\n",
    "        \n",
    "        return stages\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error con Tournament Calendar: {e}\")\n",
    "        return {}\n",
    "\n",
    "def get_available_stages_method2():\n",
    "    \"\"\"M√©todo 2: Usar MA1 b√°sico (sin filtros problem√°ticos) para obtener stages\"\"\"\n",
    "    requestParameters = {\n",
    "        \"_fmt\": \"json\",\n",
    "        \"_pgSz\": \"100\",\n",
    "        \"_pgNm\": \"1\",\n",
    "        \"_rt\": \"b\"\n",
    "    }\n",
    "    \n",
    "    sdapi_get_url = f'https://api.performfeeds.com/soccerdata/match/{outletApiKey}/'\n",
    "    \n",
    "    try:\n",
    "        print(\"   üîÑ Intentando con MA1 b√°sico...\")\n",
    "        response = requests.get(sdapi_get_url, headers=requestHeaders(), params=requestParameters)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        matches = data.get('match', [])\n",
    "        \n",
    "        stages = {}\n",
    "        for match in matches:\n",
    "            match_info = match.get('matchInfo', {})\n",
    "            competition = match_info.get('competition', {})\n",
    "            stage = match_info.get('stage', {})\n",
    "            stage_id = stage.get('id')\n",
    "            stage_name = stage.get('name', 'N/A')\n",
    "            comp_name = competition.get('name', 'N/A')\n",
    "            comp_id = competition.get('id', 'N/A')\n",
    "            \n",
    "            if stage_id and stage_id not in stages:\n",
    "                stages[stage_id] = {\n",
    "                    'name': stage_name,\n",
    "                    'competition': comp_name,\n",
    "                    'competition_id': comp_id,\n",
    "                    'start_date': stage.get('startDate', 'N/A'),\n",
    "                    'end_date': stage.get('endDate', 'N/A')\n",
    "                }\n",
    "        \n",
    "        return stages\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error con MA1 b√°sico: {e}\")\n",
    "        return {}\n",
    "\n",
    "def get_known_stages():\n",
    "    \"\"\"M√©todo 3: Stages conocidos como fallback\"\"\"\n",
    "    known_stages = {\n",
    "        # La Liga 2024-25\n",
    "        '4xu8dwf3cotp5qu0ddi50wkyc': {\n",
    "            'name': 'La Liga 2024-25',\n",
    "            'competition': 'La Liga',\n",
    "            'start_date': '2024-08-01',\n",
    "            'end_date': '2025-05-31'\n",
    "        },\n",
    "        # Premier League 2024-25 (ejemplo)\n",
    "        '2kwbbcootiqqgmrzs6o5inle5': {\n",
    "            'name': 'Premier League 2024-25',\n",
    "            'competition': 'Premier League',\n",
    "            'start_date': '2024-08-01',\n",
    "            'end_date': '2025-05-31'\n",
    "        }\n",
    "    }\n",
    "\n",
    "def get_existing_match_ids():\n",
    "    \"\"\"Lee todos los parquet existentes y obtiene los Match IDs ya procesados\"\"\"\n",
    "    folder = \"datos_opta_parquet\"\n",
    "    existing_match_ids = set()\n",
    "    \n",
    "    # Lista de archivos parquet a revisar\n",
    "    parquet_files = [\n",
    "        'player_stats.parquet',\n",
    "        'team_stats.parquet', \n",
    "        'player_xg_stats.parquet',\n",
    "        'xg_events.parquet',\n",
    "        'abp_events.parquet',\n",
    "        'team_officials.parquet'\n",
    "    ]\n",
    "    \n",
    "    print(\"üîç Revisando archivos existentes...\")\n",
    "    \n",
    "    for filename in parquet_files:\n",
    "        filepath = f\"{folder}/{filename}\"\n",
    "        if os.path.exists(filepath):\n",
    "            try:\n",
    "                df = pd.read_parquet(filepath)\n",
    "                if not df.empty and 'Match ID' in df.columns:\n",
    "                    file_match_ids = set(df['Match ID'].unique())\n",
    "                    existing_match_ids.update(file_match_ids)\n",
    "                    print(f\"   üìÑ {filename}: {len(file_match_ids)} partidos √∫nicos\")\n",
    "                else:\n",
    "                    print(f\"   üìÑ {filename}: archivo vac√≠o o sin columna Match ID\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Error leyendo {filename}: {e}\")\n",
    "        else:\n",
    "            print(f\"   üìÑ {filename}: no existe\")\n",
    "    \n",
    "    if existing_match_ids:\n",
    "        print(f\"   ‚úÖ Total Match IDs existentes: {len(existing_match_ids)}\")\n",
    "    else:\n",
    "        print(f\"   üìÅ No se encontraron datos previos - descarga completa\")\n",
    "    \n",
    "    return existing_match_ids\n",
    "\n",
    "def filter_new_matches(matches_df, existing_match_ids):\n",
    "    \"\"\"Filtra el DataFrame de partidos para quedarse solo con los nuevos\"\"\"\n",
    "    if matches_df.empty:\n",
    "        return matches_df\n",
    "    \n",
    "    if not existing_match_ids:\n",
    "        print(f\"   üÜï Todos los partidos son nuevos: {len(matches_df)}\")\n",
    "        return matches_df\n",
    "    \n",
    "    # Filtrar partidos que NO est√°n en existing_match_ids\n",
    "    new_matches = matches_df[~matches_df['Match ID'].isin(existing_match_ids)].copy()\n",
    "    \n",
    "    total_matches = len(matches_df)\n",
    "    new_matches_count = len(new_matches)\n",
    "    existing_matches_count = total_matches - new_matches_count\n",
    "    \n",
    "    print(f\"   üìä Total partidos encontrados: {total_matches}\")\n",
    "    print(f\"   ‚úÖ Ya procesados: {existing_matches_count}\")\n",
    "    print(f\"   üÜï Nuevos por procesar: {new_matches_count}\")\n",
    "    \n",
    "    if new_matches_count == 0:\n",
    "        print(f\"   üéâ ¬°Todos los partidos ya est√°n procesados!\")\n",
    "    \n",
    "    return new_matches\n",
    "\n",
    "def debug_api_calls():\n",
    "    \"\"\"Funci√≥n de debugging para probar diferentes llamadas a la API\"\"\"\n",
    "    print(\"üîß MODO DEBUG - PROBANDO LLAMADAS A LA API\")\n",
    "    \n",
    "    tests = [\n",
    "        {\n",
    "            'name': 'MA1 B√°sico (sin filtros)',\n",
    "            'url': f'https://api.performfeeds.com/soccerdata/match/{outletApiKey}/',\n",
    "            'params': {\"_fmt\": \"json\", \"_pgSz\": \"5\", \"_rt\": \"b\"}\n",
    "        },\n",
    "        {\n",
    "            'name': 'MA1 con Competition Filter',\n",
    "            'url': f'https://api.performfeeds.com/soccerdata/match/{outletApiKey}/',\n",
    "            'params': {\"_fmt\": \"json\", \"_pgSz\": \"5\", \"_rt\": \"b\", \"comp\": \"15\"}\n",
    "        },\n",
    "        {\n",
    "            'name': 'Tournament Calendar (OT2)',\n",
    "            'url': f'https://api.performfeeds.com/soccerdata/tournamentcalendar/{outletApiKey}/',\n",
    "            'params': {\"_fmt\": \"json\", \"_pgSz\": \"5\", \"_rt\": \"b\"}\n",
    "        },\n",
    "        {\n",
    "            'name': 'OT2 con Competition Filter',\n",
    "            'url': f'https://api.performfeeds.com/soccerdata/tournamentcalendar/{outletApiKey}/',\n",
    "            'params': {\"_fmt\": \"json\", \"_pgSz\": \"5\", \"_rt\": \"b\", \"comp\": \"15\"}\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for test in tests:\n",
    "        print(f\"\\nüß™ Probando: {test['name']}\")\n",
    "        try:\n",
    "            response = requests.get(test['url'], headers=requestHeaders(), params=test['params'])\n",
    "            print(f\"   Status: {response.status_code}\")\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                print(f\"   ‚úÖ √âxito - Datos obtenidos\")\n",
    "                \n",
    "                # Mostrar estructura b√°sica\n",
    "                if 'match' in data:\n",
    "                    matches = data.get('match', [])\n",
    "                    print(f\"   üìä Partidos encontrados: {len(matches)}\")\n",
    "                    if matches:\n",
    "                        first_match = matches[0]\n",
    "                        match_info = first_match.get('matchInfo', {})\n",
    "                        stage = match_info.get('stage', {})\n",
    "                        comp = match_info.get('competition', {})\n",
    "                        print(f\"   üèÜ Ejemplo - Comp: {comp.get('name', 'N/A')}, Stage: {stage.get('name', 'N/A')}\")\n",
    "                \n",
    "                elif 'tournamentCalendar' in data:\n",
    "                    tournaments = data.get('tournamentCalendar', [])\n",
    "                    print(f\"   üìÖ Tournament Calendars encontrados: {len(tournaments)}\")\n",
    "                    if tournaments:\n",
    "                        first_tc = tournaments[0]\n",
    "                        stage = first_tc.get('stage', {})\n",
    "                        comp = first_tc.get('competition', {})\n",
    "                        print(f\"   üèÜ Ejemplo - Comp: {comp.get('name', 'N/A')}, Stage: {stage.get('name', 'N/A')}\")\n",
    "                        \n",
    "            else:\n",
    "                print(f\"   ‚ùå Error {response.status_code}: {response.text[:200]}...\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   üí• Excepci√≥n: {str(e)[:200]}...\")\n",
    "    \n",
    "    print(f\"\\nüîß ¬øQuieres probar alguna llamada espec√≠fica? (s/n): \", end=\"\")\n",
    "\n",
    "def process_matchTeamStats_data(match_id):\n",
    "    \"\"\"MA2 Team Stats - MODIFICADO para incluir Team Name\"\"\"\n",
    "    # API Parameters\n",
    "    requestParameters = {\n",
    "        \"_fmt\": \"json\",\n",
    "        \"detailed\": \"yes\",\n",
    "        \"fx\": match_id,\n",
    "        \"_rt\": \"b\"\n",
    "    }\n",
    "    \n",
    "    # GET API\n",
    "    sdapi_get_url = f'https://api.performfeeds.com/soccerdata/matchstats/{outletApiKey}/'\n",
    "    response = requests.get(\n",
    "        sdapi_get_url,\n",
    "        headers=requestHeaders(),\n",
    "        params=requestParameters\n",
    "    )\n",
    "    \n",
    "    # Check response Status\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "    else:\n",
    "        print(f\"Error: API request failed with status code {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Extract data\n",
    "    match_info = data.get('matchInfo', {})\n",
    "    competition_info = match_info.get('competition', {})\n",
    "    stage_info = match_info.get('stage', {})\n",
    "    live_data = data.get('liveData', {})\n",
    "    line_ups = live_data.get('lineUp', [])\n",
    "    \n",
    "    # A√ëADIR: Obtener informaci√≥n home/away\n",
    "    home_away_info = get_home_away_info(match_info, live_data)\n",
    "\n",
    "    \n",
    "    # Create a DataFrame for team stats\n",
    "    team_stats_data = []\n",
    "    \n",
    "    # Extract team stats\n",
    "    for team_stats in line_ups:\n",
    "        team_id = team_stats['contestantId']\n",
    "        team_name = home_away_info['team_mapping'].get(team_id, {}).get('name', 'N/A')\n",
    "        team_position = home_away_info['team_mapping'].get(team_id, {}).get('position', 'N/A')\n",
    "\n",
    "        # A√ëADIR: Determinar si es home o away\n",
    "        is_home = team_id == home_away_info['home_team_id']\n",
    "        is_away = team_id == home_away_info['away_team_id']\n",
    "        \n",
    "        for stat in team_stats['stat']:\n",
    "            stat_info = {\n",
    "                'Match ID': match_info.get('id', 'N/A'),\n",
    "                'Competition ID': competition_info.get('id', 'N/A'),\n",
    "                'Competition Name': competition_info.get('name', 'N/A'),\n",
    "                'Week': match_info.get('week', 'N/A'),\n",
    "                'Stage ID': stage_info.get('id', 'N/A'),\n",
    "                'Stage Name': stage_info.get('name', 'N/A'),\n",
    "                'Team ID': team_id,\n",
    "                'Team Name': team_name,\n",
    "                'Team Position': team_position,  # A√ëADIR\n",
    "                'Is Home': is_home,  # A√ëADIR\n",
    "                'Is Away': is_away,  # A√ëADIR\n",
    "                'HT Home Score': home_away_info['ht_home'],  # A√ëADIR\n",
    "                'HT Away Score': home_away_info['ht_away'],  # A√ëADIR\n",
    "                'FT Home Score': home_away_info['ft_home'],  # A√ëADIR\n",
    "                'FT Away Score': home_away_info['ft_away'],  # A√ëADIR\n",
    "                'Stat Type': stat.get('type', 'N/A'),\n",
    "                'Total': stat.get('value', 0)\n",
    "            }\n",
    "            team_stats_data.append(stat_info)\n",
    "    \n",
    "    # Create a DataFrame and converts \"NAN\" to 0 value\n",
    "    df_team_stats = pd.DataFrame(team_stats_data)\n",
    "    if not df_team_stats.empty:\n",
    "        df_team_stats = df_team_stats.pivot(\n",
    "            index=['Team ID', 'Team Name', 'Team Position', 'Is Home', 'Is Away', \n",
    "            'HT Home Score', 'HT Away Score', 'FT Home Score', 'FT Away Score',\n",
    "            'Match ID', 'Competition ID', 'Competition Name', 'Week', 'Stage ID', 'Stage Name'],\n",
    "            columns='Stat Type', \n",
    "            values='Total'\n",
    "        ).reset_index()\n",
    "        df_team_stats = df_team_stats.fillna(0)\n",
    "        \n",
    "        # Convert all stat columns (excluding metadata) to floats\n",
    "        metadata_cols = ['Team ID', 'Team Name', 'Team Position', 'Is Home', 'Is Away', \n",
    "                        'HT Home Score', 'HT Away Score', 'FT Home Score', 'FT Away Score',\n",
    "                        'Match ID', 'Competition ID', 'Competition Name', 'Week', 'Stage ID', 'Stage Name']\n",
    "        stat_cols = [col for col in df_team_stats.columns if col not in metadata_cols]\n",
    "        for col in stat_cols:\n",
    "            df_team_stats[col] = pd.to_numeric(df_team_stats[col], errors='coerce').fillna(0).astype(float)\n",
    "    \n",
    "    return df_team_stats\n",
    "    \n",
    "\n",
    "# Funci√≥n auxiliar para testing r√°pido\n",
    "def test_stage_access():\n",
    "    \"\"\"Test r√°pido para verificar acceso a stages - MEJORADO\"\"\"\n",
    "    print(\"üîç TEST R√ÅPIDO DE ACCESO A STAGES\")\n",
    "    \n",
    "    # Test 1: Usar el stage ID que sabemos que funciona\n",
    "    known_stage = \"4xu8dwf3cotp5qu0ddi50wkyc\"\n",
    "    \n",
    "    print(f\"\\nüß™ Probando MA1 con stage conocido: {known_stage[:12]}...\")\n",
    "    \n",
    "    requestParameters = {\n",
    "        \"_fmt\": \"json\",\n",
    "        \"_pgSz\": \"5\",\n",
    "        \"stg\": known_stage,\n",
    "        \"live\": \"yes\",\n",
    "        \"_rt\": \"b\"\n",
    "    }\n",
    "    \n",
    "    sdapi_get_url = f'https://api.performfeeds.com/soccerdata/match/{outletApiKey}/'\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(sdapi_get_url, headers=requestHeaders(), params=requestParameters)\n",
    "        print(f\"Status: {response.status_code}\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            matches = data.get('match', [])\n",
    "            print(f\"‚úÖ √âxito! Partidos encontrados: {len(matches)}\")\n",
    "            \n",
    "            if matches:\n",
    "                # Mostrar info del primer partido\n",
    "                first_match = matches[0]\n",
    "                match_info = first_match.get('matchInfo', {})\n",
    "                stage = match_info.get('stage', {})\n",
    "                comp = match_info.get('competition', {})\n",
    "                week = match_info.get('week', 'N/A')\n",
    "                \n",
    "                # Verificar status del partido\n",
    "                live_data = first_match.get('liveData', {})\n",
    "                match_details = live_data.get('matchDetails', {})\n",
    "                match_status = match_details.get('matchStatus', 'N/A')\n",
    "                \n",
    "                print(f\"üìä Ejemplo partido:\")\n",
    "                print(f\"   üèÜ Competici√≥n: {comp.get('name', 'N/A')}\")\n",
    "                print(f\"   üóìÔ∏è Stage: {stage.get('name', 'N/A')}\")\n",
    "                print(f\"   üìÖ Jornada: {week}\")\n",
    "                print(f\"   ‚öΩ Status: {match_status}\")\n",
    "                \n",
    "                # Test adicional: probar con jornada espec√≠fica\n",
    "                print(f\"\\nüß™ Probando MA1 con stage + jornada espec√≠fica...\")\n",
    "                test_week_params = requestParameters.copy()\n",
    "                test_week_params[\"week\"] = \"1\"\n",
    "                \n",
    "                response2 = requests.get(sdapi_get_url, headers=requestHeaders(), params=test_week_params)\n",
    "                if response2.status_code == 200:\n",
    "                    data2 = response2.json()\n",
    "                    matches2 = data2.get('match', [])\n",
    "                    print(f\"   ‚úÖ Jornada 1: {len(matches2)} partidos encontrados\")\n",
    "                else:\n",
    "                    print(f\"   ‚ùå Error con jornada espec√≠fica: {response2.status_code}\")\n",
    "                \n",
    "                return True\n",
    "        else:\n",
    "            print(f\"‚ùå Error {response.status_code}: {response.text[:200]}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"üí• Error: {e}\")\n",
    "    \n",
    "    return False\n",
    "\n",
    "def get_available_stages(competition_id):\n",
    "    \"\"\"Obtiene stages usando m√∫ltiples m√©todos como fallback - ARREGLADO basado en debug\"\"\"\n",
    "    print(\"üîÑ Obteniendo temporadas disponibles...\")\n",
    "    \n",
    "    # M√©todo 1: Tournament Calendar b√°sico\n",
    "    stages = get_available_stages_method1()\n",
    "    if stages:\n",
    "        print(f\"   ‚úÖ Encontradas {len(stages)} temporadas con Tournament Calendar\")\n",
    "        # Filtrar por competici√≥n despu√©s\n",
    "        competition_names = {\n",
    "            '13': 'Premier League',\n",
    "            '15': ['La Liga', 'Primera Divisi√≥n'],  # M√∫ltiples nombres posibles\n",
    "            '16': 'Serie A',\n",
    "            '17': 'Bundesliga',\n",
    "            '18': 'Ligue 1',\n",
    "            '19': 'Champions League'\n",
    "        }\n",
    "        \n",
    "        target_comps = competition_names.get(competition_id, [])\n",
    "        if isinstance(target_comps, str):\n",
    "            target_comps = [target_comps]\n",
    "        \n",
    "        if target_comps:\n",
    "            filtered_stages = {}\n",
    "            for stage_id, stage_info in stages.items():\n",
    "                comp_name = stage_info.get('competition', '').lower()\n",
    "                for target_comp in target_comps:\n",
    "                    if target_comp.lower() in comp_name or comp_name in target_comp.lower():\n",
    "                        filtered_stages[stage_id] = stage_info\n",
    "                        break\n",
    "            \n",
    "            if filtered_stages:\n",
    "                print(f\"   üéØ Filtradas {len(filtered_stages)} temporadas para la competici√≥n\")\n",
    "                return filtered_stages\n",
    "        \n",
    "        # Si no se puede filtrar, devolver todas\n",
    "        return stages\n",
    "    \n",
    "    # M√©todo 2: MA1 b√°sico\n",
    "    stages = get_available_stages_method2()\n",
    "    if stages:\n",
    "        print(f\"   üîç DEBUG - Todas las temporadas encontradas:\")\n",
    "        for stage_id, stage_info in stages.items():\n",
    "            print(f\"      {stage_id[:12]}... - {stage_info.get('name', 'N/A')} - {stage_info.get('competition', 'N/A')}\")\n",
    "        \n",
    "        # Filtrar por competici√≥n\n",
    "        competition_names = {\n",
    "            '13': 'Premier League',\n",
    "            '15': ['La Liga', 'Primera Divisi√≥n'],\n",
    "            '16': 'Serie A',\n",
    "            '17': 'Bundesliga',\n",
    "            '18': 'Ligue 1',\n",
    "            '19': 'Champions League'\n",
    "        }\n",
    "        \n",
    "        target_comps = competition_names.get(competition_id, [])\n",
    "        if isinstance(target_comps, str):\n",
    "            target_comps = [target_comps]\n",
    "        \n",
    "        if target_comps:\n",
    "            filtered_stages = {}\n",
    "            for stage_id, stage_info in stages.items():\n",
    "                comp_name = stage_info.get('competition', '').lower()\n",
    "                for target_comp in target_comps:\n",
    "                    if target_comp.lower() in comp_name or comp_name in target_comp.lower():\n",
    "                        filtered_stages[stage_id] = stage_info\n",
    "                        break\n",
    "            \n",
    "            if filtered_stages:\n",
    "                print(f\"   üéØ Filtradas {len(filtered_stages)} temporadas para la competici√≥n\")\n",
    "                return filtered_stages\n",
    "        \n",
    "        return stages\n",
    "    \n",
    "    # M√©todo 3: Stages conocidos\n",
    "    print(\"   üîÑ Usando stages conocidos como fallback...\")\n",
    "    known_stages = get_known_stages()\n",
    "    \n",
    "    # Filtrar por competici√≥n\n",
    "    competition_names = {\n",
    "        '13': 'Premier League',\n",
    "        '15': 'La Liga', \n",
    "        '16': 'Serie A',\n",
    "        '17': 'Bundesliga',\n",
    "        '18': 'Ligue 1',\n",
    "        '19': 'Champions League'\n",
    "    }\n",
    "    target_comp = competition_names.get(competition_id, '')\n",
    "    if target_comp:\n",
    "        filtered_stages = {k: v for k, v in known_stages.items() \n",
    "                         if target_comp.lower() in v.get('competition', '').lower()}\n",
    "        if filtered_stages:\n",
    "            print(f\"   ‚úÖ Usando {len(filtered_stages)} temporadas conocidas\")\n",
    "            return filtered_stages\n",
    "    \n",
    "    return known_stages\n",
    "\n",
    "def get_match_ids_advanced(competition_levels=\"13,15\", max_matches=50, specific_week=None, stage_id=None):\n",
    "    \"\"\"Obtiene match IDs - ARREGLADO para evitar filtros problem√°ticos\"\"\"\n",
    "    requestParameters = {\n",
    "        \"_fmt\": \"json\",\n",
    "        \"_pgSz\": str(max_matches),\n",
    "        \"_pgNm\": \"1\",\n",
    "        \"live\": \"yes\",\n",
    "        \"_rt\": \"b\"\n",
    "        # REMOVIDO: \"status\": \"played\" - causa error 400\n",
    "        # REMOVIDO: \"cvlv\": competition_levels - causa error 403\n",
    "    }\n",
    "    \n",
    "    if specific_week:\n",
    "        requestParameters[\"week\"] = str(specific_week)\n",
    "    \n",
    "    # Usar el par√°metro 'stg' seg√∫n la documentaci√≥n MA1\n",
    "    if stage_id:\n",
    "        requestParameters[\"stg\"] = str(stage_id)\n",
    "\n",
    "    sdapi_get_url = f'https://api.performfeeds.com/soccerdata/match/{outletApiKey}/'\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(sdapi_get_url, headers=requestHeaders(), params=requestParameters)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        matches = data.get('match', [])\n",
    "        \n",
    "        match_list = []\n",
    "        for match in matches:\n",
    "            match_info = match.get('matchInfo', {})\n",
    "            match_id = match_info.get('id')\n",
    "            if match_id:\n",
    "                competition = match_info.get('competition', {})\n",
    "                stage = match_info.get('stage', {})\n",
    "                contestants = match_info.get('contestant', [])\n",
    "                teams = [{'id': c.get('id'), 'name': c.get('name'), 'code': c.get('code')} for c in contestants]\n",
    "                \n",
    "                # Verificar que el partido est√© finalizado usando liveData\n",
    "                live_data = match.get('liveData', {})\n",
    "                match_details = live_data.get('matchDetails', {})\n",
    "                match_status = match_details.get('matchStatus', '')\n",
    "                \n",
    "                # Solo incluir partidos finalizados\n",
    "                if match_status.lower() in ['played', 'finished', 'ft', 'final']:\n",
    "                    match_data = {\n",
    "                        'Match ID': match_id,\n",
    "                        'Competition': competition.get('name', 'N/A'),\n",
    "                        'Competition ID': competition.get('id', 'N/A'),\n",
    "                        'Stage ID': stage.get('id', 'N/A'),\n",
    "                        'Stage Name': stage.get('name', 'N/A'),\n",
    "                        'Date': match_info.get('date', 'N/A'),\n",
    "                        'Week': match_info.get('week', 'N/A'),\n",
    "                        'Match Status': match_status,\n",
    "                        'Teams': teams\n",
    "                    }\n",
    "                    match_list.append(match_data)\n",
    "        \n",
    "        return pd.DataFrame(match_list)\n",
    "    except Exception as e:\n",
    "        print(f\"Error obteniendo partidos: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# ====================================\n",
    "# EXTRACTORES - COPIADOS DE LA NOTEBOOK QUE FUNCIONA\n",
    "# ====================================\n",
    "\n",
    "def process_matchPlayerStats_data(match_id):\n",
    "    \"\"\"MA2 Player Stats + Team Officials - CORREGIDO COMPLETAMENTE\"\"\"\n",
    "    # API Parameters\n",
    "    requestParameters = {\n",
    "        \"_fmt\": \"json\",\n",
    "        \"detailed\": \"yes\",\n",
    "        \"fx\": match_id,\n",
    "        \"_rt\": \"b\"\n",
    "    }\n",
    "    \n",
    "    # GET API\n",
    "    sdapi_get_url = f'https://api.performfeeds.com/soccerdata/matchstats/{outletApiKey}/'\n",
    "    response = requests.get(\n",
    "        sdapi_get_url,\n",
    "        headers=requestHeaders(),\n",
    "        params=requestParameters\n",
    "    )\n",
    "    \n",
    "    # Check response Status\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "    else:\n",
    "        print(f\"Error: API request failed with status code {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    # Extract data\n",
    "    match_info = data.get('matchInfo', {})\n",
    "    competition_info = match_info.get('competition', {})\n",
    "    stage_info = match_info.get('stage', {})\n",
    "    live_data = data.get('liveData', {})\n",
    "    line_ups = live_data.get('lineUp', [])\n",
    "    \n",
    "    # A√ëADIR: Obtener informaci√≥n home/away\n",
    "    home_away_info = get_home_away_info(match_info, live_data)\n",
    "    \n",
    "    # Create a DataFrame for player stats\n",
    "    player_stats_data = []\n",
    "    \n",
    "    # Extract player stats\n",
    "    for line_up in line_ups:\n",
    "        team_id = line_up.get('contestantId')\n",
    "        team_name = home_away_info['team_mapping'].get(team_id, {}).get('name', 'N/A')\n",
    "        team_position = home_away_info['team_mapping'].get(team_id, {}).get('position', 'N/A')\n",
    "                \n",
    "        # A√ëADIR: Determinar si es home o away\n",
    "        is_home = team_id == home_away_info['home_team_id']\n",
    "        is_away = team_id == home_away_info['away_team_id']\n",
    "        \n",
    "        for player in line_up.get('player', []):\n",
    "            player_entry = {\n",
    "                'Match ID': match_info.get('id', 'N/A'),\n",
    "                'Competition ID': competition_info.get('id', 'N/A'),\n",
    "                'Competition Name': competition_info.get('name', 'N/A'),\n",
    "                'Week': match_info.get('week', 'N/A'),\n",
    "                'Stage ID': stage_info.get('id', 'N/A'),\n",
    "                'Stage Name': stage_info.get('name', 'N/A'),\n",
    "                'Team ID': team_id,\n",
    "                'Team Name': team_name,\n",
    "                'Team Position': team_position,  # A√ëADIR\n",
    "                'Is Home': is_home,  # A√ëADIR\n",
    "                'Is Away': is_away,  # A√ëADIR\n",
    "                'HT Home Score': home_away_info['ht_home'],  # A√ëADIR\n",
    "                'HT Away Score': home_away_info['ht_away'],  # A√ëADIR\n",
    "                'FT Home Score': home_away_info['ft_home'],  # A√ëADIR\n",
    "                'FT Away Score': home_away_info['ft_away'],  # A√ëADIR\n",
    "                'Player ID': player.get('playerId', 'N/A'),\n",
    "                'First Name': player.get('firstName', 'N/A'),\n",
    "                'Last Name': player.get('lastName', 'N/A'),\n",
    "                'Match Name': player.get('matchName', 'N/A'),\n",
    "                'Shirt Number': player.get('shirtNumber', 'N/A'),\n",
    "                'Position': player.get('position', 'N/A'),\n",
    "                'Position Side': player.get('positionSide', 'N/A'),\n",
    "                'Formation Place': player.get('formationPlace', 'N/A'),\n",
    "            }\n",
    "            \n",
    "            for stat in player.get('stat', []):\n",
    "                stat_type = stat.get('type', '')\n",
    "                stat_value = stat.get('value', 0)\n",
    "                player_entry[stat_type] = stat_value\n",
    "            \n",
    "            player_stats_data.append(player_entry)\n",
    "    \n",
    "    # Create a DataFrame for team officials\n",
    "    team_officials_data = []\n",
    "    \n",
    "    # Extract team officials\n",
    "    for line_up in line_ups:\n",
    "        team_id = line_up.get('contestantId')\n",
    "        team_name = home_away_info['team_mapping'].get(team_id, {}).get('name', 'N/A')\n",
    "        \n",
    "        for official in line_up.get('teamOfficial', []):\n",
    "            official_entry = {\n",
    "                'Match ID': match_info.get('id', 'N/A'),\n",
    "                'Competition ID': competition_info.get('id', 'N/A'),\n",
    "                'Competition Name': competition_info.get('name', 'N/A'),\n",
    "                'Week': match_info.get('week', 'N/A'),\n",
    "                'Stage ID': stage_info.get('id', 'N/A'),\n",
    "                'Stage Name': stage_info.get('name', 'N/A'),\n",
    "                'Team ID': team_id,\n",
    "                'Team Name': team_name,\n",
    "                'Official ID': official.get('id', 'N/A'),\n",
    "                'First Name': official.get('firstName', 'N/A'),\n",
    "                'Last Name': official.get('lastName', 'N/A'),\n",
    "                'Short First Name': official.get('shortFirstName', 'N/A'),\n",
    "                'Short Last Name': official.get('shortlastName', 'N/A'),\n",
    "                'Known Name': official.get('knownName', 'N/A'),\n",
    "                'Type': official.get('type', 'N/A')\n",
    "            }\n",
    "            team_officials_data.append(official_entry)\n",
    "    \n",
    "    # Create DataFrames and convert \"NAN\" to 0 value\n",
    "    df_player_stats = pd.DataFrame(player_stats_data).fillna(0)\n",
    "    df_team_officials = pd.DataFrame(team_officials_data).fillna('N/A')\n",
    "    \n",
    "    # Convert all stat columns (excluding metadata) to numeric for player stats\n",
    "    non_stat_cols = ['Match ID', 'Competition ID', 'Competition Name', 'Week', 'Stage ID', 'Stage Name', \n",
    "                     'Team ID', 'Team Name', 'Team Position', 'Is Home', 'Is Away', \n",
    "                     'HT Home Score', 'HT Away Score', 'FT Home Score', 'FT Away Score',\n",
    "                     'Player ID', 'First Name', 'Last Name', 'Match Name',\n",
    "                     'Shirt Number', 'Position', 'Position Side', 'Formation Place']\n",
    "    \n",
    "    if not df_player_stats.empty:\n",
    "        stat_cols = [col for col in df_player_stats.columns if col not in non_stat_cols]\n",
    "        \n",
    "        for col in stat_cols:\n",
    "            df_player_stats[col] = pd.to_numeric(df_player_stats[col], errors='coerce').fillna(0)\n",
    "        \n",
    "        # Optionally, convert all floats to ints if appropriate\n",
    "        df_player_stats[stat_cols] = df_player_stats[stat_cols].astype(float)\n",
    "    \n",
    "    return df_player_stats, df_team_officials\n",
    "\n",
    "def process_match_events_data(match_id):\n",
    "    \"\"\"MA3 Match Events - CORREGIDO\"\"\"\n",
    "    # API Parameters\n",
    "    requestParameters = {\n",
    "        \"_fmt\": \"json\",\n",
    "        \"fx\": match_id,\n",
    "        \"_rt\": \"b\"\n",
    "    }\n",
    "    \n",
    "    # GET API\n",
    "    sdapi_get_url = f'https://api.performfeeds.com/soccerdata/matchevent/{outletApiKey}/'\n",
    "    response = requests.get(\n",
    "        sdapi_get_url,\n",
    "        headers=requestHeaders(),\n",
    "        params=requestParameters\n",
    "    )\n",
    "    \n",
    "    # Check response Status\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "    else:\n",
    "        print(f\"Error: API request failed with status code {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Extract data\n",
    "    match_info = data.get('matchInfo', {})\n",
    "    competition_info = match_info.get('competition', {})\n",
    "    stage_info = match_info.get('stage', {})\n",
    "    live_data = data.get('liveData', {})\n",
    "    events = live_data.get('event', [])\n",
    "    \n",
    "    # A√ëADIR: Obtener informaci√≥n home/away\n",
    "    home_away_info = get_home_away_info(match_info, live_data)\n",
    "    \n",
    "    # Find all unique qualifier IDs\n",
    "    qualifier_ids = set()\n",
    "    for event in events:\n",
    "        for q in event.get('qualifier', []):\n",
    "            qualifier_ids.add(str(q.get('qualifierId', '')))\n",
    "    \n",
    "    # Initialize DataFrame columns\n",
    "    columns = [\n",
    "        'Match ID', 'Competition ID', 'Competition Name', 'Week', 'Stage ID', 'Stage Name',\n",
    "        'EventId', 'timeStamp', 'contestantId', 'Team ID', 'Team Name', 'Team Position',\n",
    "        'Is Home', 'Is Away', 'HT Home Score', 'HT Away Score', 'FT Home Score', 'FT Away Score',\n",
    "        'periodId', 'timeMin', 'timeSec', 'playerId', 'playerName', 'typeId', 'Event Name', \n",
    "        'outcome', 'x', 'y'\n",
    "    ] + [f'qualifier {qid}' for qid in qualifier_ids]\n",
    "    \n",
    "    # Create a DataFrame for events\n",
    "    events_data = []\n",
    "    \n",
    "    for event in events:\n",
    "        contestant_id = event.get('contestantId', None)\n",
    "        team_name = home_away_info['team_mapping'].get(contestant_id, {}).get('name', 'N/A') if contestant_id else 'N/A'\n",
    "        team_position = home_away_info['team_mapping'].get(contestant_id, {}).get('position', 'N/A') if contestant_id else 'N/A'\n",
    "        \n",
    "        # A√ëADIR: Determinar si es home o away\n",
    "        is_home = contestant_id == home_away_info['home_team_id']\n",
    "        is_away = contestant_id == home_away_info['away_team_id']\n",
    "        \n",
    "        type_id = event.get('typeId', None)\n",
    "        event_name = EVENT_TYPE_MAPPING.get(type_id, 'Unknown Event') if type_id else 'Unknown Event'\n",
    "        \n",
    "        event_info = {\n",
    "            'Match ID': match_info.get('id', 'N/A'),\n",
    "            'Competition ID': competition_info.get('id', 'N/A'),\n",
    "            'Competition Name': competition_info.get('name', 'N/A'),\n",
    "            'Week': match_info.get('week', 'N/A'),\n",
    "            'Stage ID': stage_info.get('id', 'N/A'),\n",
    "            'Stage Name': stage_info.get('name', 'N/A'),\n",
    "            'EventId': event.get('eventId', None),\n",
    "            'typeId': type_id,\n",
    "            'Event Name': event_name,\n",
    "            'periodId': event.get('periodId', None),\n",
    "            'timeMin': event.get('timeMin', None),\n",
    "            'timeSec': event.get('timeSec', None),\n",
    "            'contestantId': contestant_id,\n",
    "            'Team ID': contestant_id,\n",
    "            'Team Name': team_name,\n",
    "            'Team Position': team_position,  # A√ëADIR\n",
    "            'Is Home': is_home,  # A√ëADIR\n",
    "            'Is Away': is_away,  # A√ëADIR\n",
    "            'HT Home Score': home_away_info['ht_home'],  # A√ëADIR\n",
    "            'HT Away Score': home_away_info['ht_away'],  # A√ëADIR\n",
    "            'FT Home Score': home_away_info['ft_home'],  # A√ëADIR\n",
    "            'FT Away Score': home_away_info['ft_away'],  # A√ëADIR\n",
    "            'playerId': event.get('playerId', None),\n",
    "            'playerName': event.get('playerName', None),\n",
    "            'outcome': event.get('outcome', None),\n",
    "            'x': event.get('x', None),\n",
    "            'y': event.get('y', None),\n",
    "            'timeStamp': event.get('timeStamp', None),\n",
    "        }\n",
    "        \n",
    "        # Initialize all qualifiers to 0\n",
    "        for qid in qualifier_ids:\n",
    "            event_info[f'qualifier {qid}'] = 0\n",
    "        \n",
    "        # Update with actual qualifier values\n",
    "        for q in event.get('qualifier', []):\n",
    "            event_info[f'qualifier {q[\"qualifierId\"]}'] = q.get('value', None)\n",
    "        \n",
    "        events_data.append(event_info)\n",
    "    \n",
    "    events_df = pd.DataFrame(events_data, columns=columns)\n",
    "    return events_df\n",
    "\n",
    "def process_xG_matchPlayerStats_data(match_id):\n",
    "    \"\"\"MA12 Player xG Stats + Team Officials - MODIFICADO para incluir teamOfficial\"\"\"\n",
    "    # API Parameters\n",
    "    requestParameters = {\n",
    "        \"_fmt\": \"json\",\n",
    "        \"fx\": match_id,\n",
    "        \"_rt\": \"b\"\n",
    "    }\n",
    "    \n",
    "    # GET API\n",
    "    sdapi_get_url = f'https://api.performfeeds.com/soccerdata/matchexpectedgoals/{outletApiKey}/'\n",
    "    response = requests.get(\n",
    "        sdapi_get_url,\n",
    "        headers=requestHeaders(),\n",
    "        params=requestParameters\n",
    "    )\n",
    "    \n",
    "    # Create DataFrames for xG player stats and team officials\n",
    "    player_xGstats_data = []\n",
    "    team_officials_data = []\n",
    "    \n",
    "    # Check response Status\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extract data\n",
    "        match_info = data.get('matchInfo', {})\n",
    "        competition_info = match_info.get('competition', {})\n",
    "        stage_info = match_info.get('stage', {})\n",
    "        live_data = data.get('liveData', {})\n",
    "        line_ups = live_data.get('lineUp', [])\n",
    "        \n",
    "        # A√ëADIR: Obtener informaci√≥n home/away\n",
    "        home_away_info = get_home_away_info(match_info, live_data)\n",
    "        \n",
    "        # Extract player stats\n",
    "        for line_up in line_ups:\n",
    "            team_id = line_up.get('contestantId')\n",
    "            team_name = home_away_info['team_mapping'].get(team_id, {}).get('name', 'N/A')            \n",
    "            for player in line_up.get('player', []):\n",
    "                player_entry = {\n",
    "                    'Match ID': match_info.get('id', 'N/A'),\n",
    "                    'Competition ID': competition_info.get('id', 'N/A'),\n",
    "                    'Competition Name': competition_info.get('name', 'N/A'),\n",
    "                    'Week': match_info.get('week', 'N/A'),\n",
    "                    'Stage ID': stage_info.get('id', 'N/A'),\n",
    "                    'Stage Name': stage_info.get('name', 'N/A'),\n",
    "                    'Team ID': team_id,\n",
    "                    'Team Name': team_name,\n",
    "                    'Player ID': player.get('playerId', 'N/A'),\n",
    "                    'First Name': player.get('firstName', 'N/A'),\n",
    "                    'Last Name': player.get('lastName', 'N/A'),\n",
    "                    'Match Name': player.get('matchName', 'N/A'),\n",
    "                    'Shirt Number': player.get('shirtNumber', 'N/A'),\n",
    "                    'Position': player.get('position', 'N/A'),\n",
    "                    'Position Side': player.get('positionSide', 'N/A'),\n",
    "                    'Formation Place': player.get('formationPlace', 'N/A'),\n",
    "                }\n",
    "                \n",
    "                for stat in player.get('stat', []):\n",
    "                    stat_type = stat.get('type', '')\n",
    "                    stat_value = stat.get('value', 0)\n",
    "                    player_entry[stat_type] = stat_value\n",
    "                \n",
    "                player_xGstats_data.append(player_entry)\n",
    "            \n",
    "            # Extract team officials\n",
    "            for official in line_up.get('teamOfficial', []):\n",
    "                official_entry = {\n",
    "                    'Match ID': match_info.get('id', 'N/A'),\n",
    "                    'Competition ID': competition_info.get('id', 'N/A'),\n",
    "                    'Competition Name': competition_info.get('name', 'N/A'),\n",
    "                    'Week': match_info.get('week', 'N/A'),\n",
    "                    'Stage ID': stage_info.get('id', 'N/A'),\n",
    "                    'Stage Name': stage_info.get('name', 'N/A'),\n",
    "                    'Team ID': team_id,\n",
    "                    'Team Name': team_name,  # En MA12 firstName contiene el nombre del equipo seg√∫n tu comentario\n",
    "                    'Official ID': official.get('id', 'N/A'),\n",
    "                    'First Name': official.get('firstName', 'N/A'),\n",
    "                    'Last Name': official.get('lastName', 'N/A'),\n",
    "                    'Short First Name': official.get('shortFirstName', 'N/A'),\n",
    "                    'Short Last Name': official.get('shortlastName', 'N/A'),\n",
    "                    'Known Name': official.get('knownName', 'N/A'),\n",
    "                    'Type': official.get('type', 'N/A')\n",
    "                }\n",
    "                team_officials_data.append(official_entry)\n",
    "    \n",
    "    else:\n",
    "        print(f\"Error: API request failed with status code {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    # Create DataFrames and convert \"NAN\" to 0 value\n",
    "    df_player_xGstats = pd.DataFrame(player_xGstats_data).fillna(0)\n",
    "    df_team_officials = pd.DataFrame(team_officials_data).fillna('N/A')\n",
    "    \n",
    "    # Convert all stat columns (excluding metadata) to numeric for player xG stats\n",
    "    non_stat_cols = ['Match ID', 'Competition ID', 'Competition Name', 'Week', 'Stage ID', 'Stage Name', \n",
    "                     'Team ID', 'Team Name', 'Player ID', 'First Name', 'Last Name', 'Match Name',\n",
    "                     'Shirt Number', 'Position', 'Position Side', 'Formation Place']\n",
    "    \n",
    "    if not df_player_xGstats.empty:\n",
    "        stat_cols = [col for col in df_player_xGstats.columns if col not in non_stat_cols]\n",
    "        \n",
    "        for col in stat_cols:\n",
    "            df_player_xGstats[col] = pd.to_numeric(df_player_xGstats[col], errors='coerce').fillna(0)\n",
    "        \n",
    "        # Optionally, convert all floats to ints if appropriate\n",
    "        df_player_xGstats[stat_cols] = df_player_xGstats[stat_cols].astype(float)\n",
    "    \n",
    "    return df_player_xGstats, df_team_officials\n",
    "\n",
    "def process_xG_match_events(match_id):\n",
    "    \"\"\"MA12 xG Events - CORREGIDO\"\"\"\n",
    "    # API Parameters\n",
    "    requestParameters = {\n",
    "        \"_rt\": \"b\",\n",
    "        \"_fmt\": \"json\",\n",
    "        \"fx\": match_id\n",
    "    }\n",
    "    \n",
    "    # GET API\n",
    "    sdapi_get_url = f'https://api.performfeeds.com/soccerdata/matchexpectedgoals/{outletApiKey}/'\n",
    "    \n",
    "    response = requests.get(\n",
    "        sdapi_get_url,\n",
    "        headers=requestHeaders(),\n",
    "        params=requestParameters\n",
    "    )\n",
    "    \n",
    "    # Check response Status\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "    else:\n",
    "        print(f\"Error: API request failed with status code {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Extract event data\n",
    "    match_info = data.get('matchInfo', {})\n",
    "    competition_info = match_info.get('competition', {})\n",
    "    stage_info = match_info.get('stage', {})\n",
    "    live_data = data.get('liveData', {})\n",
    "    xG_events = live_data.get('event', [])\n",
    "    \n",
    "    # A√ëADIR: Obtener informaci√≥n home/away\n",
    "    home_away_info = get_home_away_info(match_info, live_data)\n",
    "    \n",
    "    # Find all unique qualifier IDs\n",
    "    qualifier_ids = {'321', '322'}\n",
    "    \n",
    "    # Initialize DataFrame columns\n",
    "    columns = [\n",
    "        'Match ID', 'Competition ID', 'Competition Name', 'Week', 'Stage ID', 'Stage Name', 'EventId', 'timeStamp', \n",
    "        'contestantId', 'Team ID', 'Team Name', 'periodId', 'timeMin', 'timeSec',\n",
    "        'playerId', 'playerName', 'typeId', 'Event Name', 'outcome', 'x', 'y'] + [f'qualifier {qid}' for qid in qualifier_ids]\n",
    "    \n",
    "    # Create a DataFrame for xG events\n",
    "    xG_events_data = []\n",
    "    \n",
    "    for event in xG_events:\n",
    "        contestant_id = event.get('contestantId', None)\n",
    "        team_name = home_away_info['team_mapping'].get(contestant_id, {}).get('name', 'N/A') if contestant_id else 'N/A'  # CORREGIDO\n",
    "        type_id = event.get('typeId', None)\n",
    "        event_name = EVENT_TYPE_MAPPING.get(type_id, 'Unknown Event') if type_id else 'Unknown Event'\n",
    "        \n",
    "        xG_event_info = {\n",
    "            'Match ID': match_info.get('id', 'N/A'),\n",
    "            'Competition ID': competition_info.get('id', 'N/A'),\n",
    "            'Competition Name': competition_info.get('name', 'N/A'),\n",
    "            'Week': match_info.get('week', 'N/A'),\n",
    "            'Stage ID': stage_info.get('id', 'N/A'),\n",
    "            'Stage Name': stage_info.get('name', 'N/A'),\n",
    "            'EventId': event.get('eventId', None),\n",
    "            'typeId': type_id,\n",
    "            'Event Name': event_name,\n",
    "            'periodId': event.get('periodId', None),\n",
    "            'timeMin': event.get('timeMin', None),\n",
    "            'timeSec': event.get('timeSec', None),\n",
    "            'contestantId': contestant_id,\n",
    "            'Team ID': contestant_id,\n",
    "            'Team Name': team_name,\n",
    "            'playerId': event.get('playerId', None),\n",
    "            'playerName': event.get('playerName', None),\n",
    "            'outcome': event.get('outcome', None),\n",
    "            'x': event.get('x', None),\n",
    "            'y': event.get('y', None),\n",
    "            'timeStamp': event.get('timeStamp', None),\n",
    "        }\n",
    "        \n",
    "        for qid in qualifier_ids:\n",
    "            xG_event_info[f'qualifier {qid}'] = 0\n",
    "        \n",
    "        # Update with actual qualifier values\n",
    "        for q in event.get('qualifier', []):\n",
    "            xG_event_info[f'qualifier {q[\"qualifierId\"]}'] = q.get('value', None)\n",
    "        \n",
    "        xG_events_data.append(xG_event_info)\n",
    "    \n",
    "    xG_events_df = pd.DataFrame(xG_events_data, columns=columns)\n",
    "    return xG_events_df\n",
    "\n",
    "# ====================================\n",
    "# FUNCIONES PRINCIPALES - MODIFICADAS\n",
    "# ====================================\n",
    "def get_current_season_stage():\n",
    "    \"\"\"Obtiene el Stage ID de la temporada actual (que no sea 23/24 ni 24/25)\"\"\"\n",
    "    known_stages = ['49d7kwlzobzuyja3x2bzwe3o4', '4xu8dwf3cotp5qu0ddi50wkyc']\n",
    "    \n",
    "    # Usar el m√©todo que ya funciona para obtener stages\n",
    "    stages = get_available_stages_method2()\n",
    "    \n",
    "    for stage_id, stage_info in stages.items():\n",
    "        comp_name = stage_info.get('competition', '').lower()\n",
    "        if 'primera' in comp_name or 'la liga' in comp_name:\n",
    "            if stage_id not in known_stages:\n",
    "                return stage_id\n",
    "    \n",
    "    return None\n",
    "    \n",
    "def interactive_competition_selection():\n",
    "    \"\"\"Selecci√≥n simplificada solo para temporadas de La Liga\"\"\"\n",
    "    print(\"\\nüá™üá∏ LA LIGA - SELECCIONA TEMPORADA:\")\n",
    "    \n",
    "    current_stage = get_current_season_stage()\n",
    "    \n",
    "    seasons = {\n",
    "        '1': {\n",
    "            'name': '2023/24',\n",
    "            'stage_id': '49d7kwlzobzuyja3x2bzwe3o4'\n",
    "        },\n",
    "        '2': {\n",
    "            'name': '2024/25', \n",
    "            'stage_id': '4xu8dwf3cotp5qu0ddi50wkyc'\n",
    "        },\n",
    "        '3': {\n",
    "            'name': '2025/26',\n",
    "            'stage_id': current_stage\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for key, season in seasons.items():\n",
    "        status = \"‚úÖ\" if season['stage_id'] else \"‚ùå\"\n",
    "        print(f\"  {key}: Temporada {season['name']} {status}\")\n",
    "    \n",
    "    choice = input(f\"\\nüóìÔ∏è Selecciona temporada (1-3): \").strip()\n",
    "    \n",
    "    if choice in seasons:\n",
    "        selected = seasons[choice]\n",
    "        max_week = int(input(f\"\\nüìÖ ¬øHasta qu√© jornada descargar? (ej: 2): \").strip())\n",
    "        \n",
    "        return {\n",
    "            'competition_id': '15',\n",
    "            'stage_id': selected['stage_id'],\n",
    "            'stage_name': f\"La Liga {selected['name']}\",\n",
    "            'max_week': max_week\n",
    "        }\n",
    "    else:\n",
    "        print(\"‚ùå Selecci√≥n no v√°lida\")\n",
    "        return None\n",
    "\n",
    "def get_matches_by_weeks(competition_id, stage_id, max_week):\n",
    "    \"\"\"Obtiene partidos por jornadas - ARREGLADO para usar solo stage_id\"\"\"\n",
    "    all_matches = []\n",
    "    \n",
    "    for week in range(1, max_week + 1):\n",
    "        print(f\"üìÖ Jornada {week}...\")\n",
    "        matches_df = get_match_ids_advanced(\n",
    "            max_matches=50,\n",
    "            specific_week=str(week),\n",
    "            stage_id=stage_id  # Solo usamos stage_id, no competition_levels\n",
    "        )\n",
    "        \n",
    "        if not matches_df.empty:\n",
    "            print(f\"   ‚úÖ Encontrados {len(matches_df)} partidos en jornada {week}\")\n",
    "            all_matches.append(matches_df)\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è No se encontraron partidos en jornada {week}\")\n",
    "        time.sleep(2)\n",
    "    \n",
    "    if all_matches:\n",
    "        result_df = pd.concat(all_matches, ignore_index=True)\n",
    "        print(f\"\\nüìä Total partidos encontrados: {len(result_df)}\")\n",
    "        return result_df\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "def save_to_parquet(data_dict, filename_prefix=None):\n",
    "    \"\"\"Guarda datos en parquet de forma incremental - VERSI√ìN DEFINITIVA\"\"\"\n",
    "    folder = \"datos_opta_parquet\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    \n",
    "    # Nombres fijos para los archivos y sus claves de duplicaci√≥n\n",
    "    file_config = {\n",
    "        'player_stats': {\n",
    "            'filename': 'player_stats.parquet',\n",
    "            'duplicate_keys': ['Match ID', 'Player ID']\n",
    "        },\n",
    "        'team_stats': {\n",
    "            'filename': 'team_stats.parquet', \n",
    "            'duplicate_keys': ['Match ID', 'Team ID']\n",
    "        },\n",
    "        'player_xg_stats': {\n",
    "            'filename': 'player_xg_stats.parquet',\n",
    "            'duplicate_keys': ['Match ID', 'Player ID']\n",
    "        },\n",
    "        'xg_events': {\n",
    "            'filename': 'xg_events.parquet',\n",
    "            'duplicate_keys': ['Match ID', 'EventId']\n",
    "        },\n",
    "        'match_events': {\n",
    "            'filename': 'abp_events.parquet',\n",
    "            'duplicate_keys': ['Match ID', 'EventId']\n",
    "        },\n",
    "        'team_officials': {\n",
    "            'filename': 'team_officials.parquet',\n",
    "            'duplicate_keys': ['Match ID', 'Team ID', 'Official ID']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for data_type, df in data_dict.items():\n",
    "        if not df.empty and data_type in file_config:\n",
    "            config = file_config[data_type]\n",
    "            filename = f\"{folder}/{config['filename']}\"\n",
    "            duplicate_keys = config['duplicate_keys']\n",
    "            \n",
    "            print(f\"üîÑ Procesando {data_type}...\")\n",
    "            \n",
    "            try:\n",
    "                # PASO 1: Crear una copia para no modificar el original\n",
    "                df_copy = df.copy()\n",
    "                \n",
    "                # PASO 2: Conversi√≥n ROBUSTA de tipos de datos\n",
    "                print(f\"   üìù Limpiando tipos de datos...\")\n",
    "                \n",
    "                # Convertir TODAS las columnas qualifier a string sin excepciones\n",
    "                qualifier_cols = [col for col in df_copy.columns if col.startswith('qualifier')]\n",
    "                for col in qualifier_cols:\n",
    "                    try:\n",
    "                        # Forzar conversi√≥n a string manejando todos los casos\n",
    "                        df_copy[col] = df_copy[col].fillna('0').astype(str)\n",
    "                        # Limpiar valores problem√°ticos\n",
    "                        df_copy[col] = df_copy[col].replace(['nan', 'None', 'null', ''], '0')\n",
    "                    except Exception as e:\n",
    "                        print(f\"   ‚ö†Ô∏è Error en columna {col}: {e}\")\n",
    "                        df_copy[col] = '0'  # Valor por defecto\n",
    "                \n",
    "                # Convertir columnas booleanas a string\n",
    "                bool_cols = [col for col in df_copy.columns if col in ['Is Home', 'Is Away']]\n",
    "                for col in bool_cols:\n",
    "                    try:\n",
    "                        df_copy[col] = df_copy[col].astype(str)\n",
    "                    except:\n",
    "                        df_copy[col] = 'False'\n",
    "                \n",
    "                # Convertir columnas num√©ricas problem√°ticas\n",
    "                numeric_cols = [col for col in df_copy.columns if col in ['timeMin', 'timeSec', 'x', 'y', 'eventId', 'EventId', 'periodId']]\n",
    "                for col in numeric_cols:\n",
    "                    try:\n",
    "                        df_copy[col] = pd.to_numeric(df_copy[col], errors='coerce')\n",
    "                    except:\n",
    "                        df_copy[col] = None\n",
    "                \n",
    "                # Limpiar TODAS las columnas object\n",
    "                for col in df_copy.columns:\n",
    "                    if df_copy[col].dtype == 'object':\n",
    "                        try:\n",
    "                            df_copy[col] = df_copy[col].fillna('N/A').astype(str)\n",
    "                            df_copy[col] = df_copy[col].replace(['nan', 'None', 'null'], 'N/A')\n",
    "                        except:\n",
    "                            df_copy[col] = 'N/A'\n",
    "                \n",
    "                # PASO 3: Intentar guardar el archivo\n",
    "                if os.path.exists(filename):\n",
    "                    existing_df = pd.read_parquet(filename)\n",
    "                    \n",
    "                    # Verificar claves de duplicaci√≥n\n",
    "                    available_keys = [key for key in duplicate_keys if key in df_copy.columns and key in existing_df.columns]\n",
    "                    \n",
    "                    if available_keys:\n",
    "                        combined_df = pd.concat([existing_df, df_copy], ignore_index=True)\n",
    "                        combined_df = combined_df.drop_duplicates(subset=available_keys, keep='last')\n",
    "                        print(f\"üíæ Actualizado: {filename} ({len(existing_df)} ‚Üí {len(combined_df)} filas)\")\n",
    "                        combined_df.to_parquet(filename, index=False)\n",
    "                    else:\n",
    "                        combined_df = pd.concat([existing_df, df_copy], ignore_index=True)\n",
    "                        print(f\"üíæ Actualizado (sin deduplicaci√≥n): {filename} ({len(existing_df)} ‚Üí {len(combined_df)} filas)\")\n",
    "                        combined_df.to_parquet(filename, index=False)\n",
    "                else:\n",
    "                    print(f\"üíæ Creado: {filename} ({len(df_copy)} filas)\")\n",
    "                    df_copy.to_parquet(filename, index=False)\n",
    "                    \n",
    "                print(f\"   ‚úÖ {data_type} guardado exitosamente\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error con parquet en {data_type}: {e}\")\n",
    "                print(f\"   üîÑ Intentando guardar como CSV...\")\n",
    "                \n",
    "                # FALLBACK: Guardar como CSV\n",
    "                try:\n",
    "                    csv_filename = filename.replace('.parquet', '.csv')\n",
    "                    df_copy.to_csv(csv_filename, index=False)\n",
    "                    print(f\"üíæ Guardado como CSV: {csv_filename}\")\n",
    "                except Exception as e2:\n",
    "                    print(f\"‚ùå Error tambi√©n con CSV: {e2}\")\n",
    "                    \n",
    "                    # √öLTIMO RECURSO: Guardar solo metadatos\n",
    "                    try:\n",
    "                        metadata_filename = filename.replace('.parquet', '_metadata.txt')\n",
    "                        with open(metadata_filename, 'w') as f:\n",
    "                            f.write(f\"Data type: {data_type}\\n\")\n",
    "                            f.write(f\"Rows: {len(df_copy)}\\n\")\n",
    "                            f.write(f\"Columns: {list(df_copy.columns)}\\n\")\n",
    "                            f.write(f\"Error: {str(e)}\\n\")\n",
    "                        print(f\"üìù Metadatos guardados: {metadata_filename}\")\n",
    "                    except:\n",
    "                        print(f\"üí• Error total con {data_type} - omitiendo...\")\n",
    "                        \n",
    "        elif not df.empty:\n",
    "            print(f\"‚ö†Ô∏è Tipo de datos desconocido: {data_type} - omitido\")\n",
    "        else:\n",
    "            print(f\"üìÑ {data_type}: DataFrame vac√≠o - omitido\")\n",
    "\n",
    "def main_interactive():\n",
    "    \"\"\"Funci√≥n principal - MODIFICADA para descarga incremental\"\"\"\n",
    "    print(\"üéØ EXTRACCI√ìN OPTA - MA2, MA3 Y MA12 CON SELECCI√ìN DE TEMPORADA\")\n",
    "    \n",
    "    config = interactive_competition_selection()\n",
    "    if not config:\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\n‚úÖ Configuraci√≥n:\")\n",
    "    print(f\"   üèÜ Competici√≥n: {config['competition_id']}\")\n",
    "    print(f\"   üóìÔ∏è Temporada: {config['stage_name']}\")\n",
    "    print(f\"   üìÖ Jornadas: 1-{config['max_week']}\")\n",
    "    print(f\"   üìä Feeds: MA2 (Match Stats), MA3 (Events), MA12 (xG)\")\n",
    "    \n",
    "    # NUEVO: Obtener Match IDs ya procesados\n",
    "    existing_match_ids = get_existing_match_ids()\n",
    "    \n",
    "    print(\"\\nüîÑ Obteniendo partidos...\")\n",
    "    all_matches_df = get_matches_by_weeks(config['competition_id'], config['stage_id'], config['max_week'])\n",
    "    \n",
    "    if all_matches_df.empty:\n",
    "        print(\"‚ùå No se encontraron partidos\")\n",
    "        print(\"\\nüîß POSIBLES SOLUCIONES:\")\n",
    "        print(\"   1. Verificar que el Stage ID sea correcto\")\n",
    "        print(\"   2. Probar con una jornada espec√≠fica que sepas que tiene partidos\")\n",
    "        print(\"   3. Verificar permisos de API\")\n",
    "        return None\n",
    "    \n",
    "    # NUEVO: Filtrar solo partidos nuevos\n",
    "    print(\"\\nüîç Filtrando partidos nuevos...\")\n",
    "    new_matches_df = filter_new_matches(all_matches_df, existing_match_ids)\n",
    "    \n",
    "    if new_matches_df.empty:\n",
    "        print(\"üéâ ¬°No hay partidos nuevos que procesar!\")\n",
    "        print(\"üíæ Los archivos existentes ya contienen todos los datos solicitados.\")\n",
    "        \n",
    "        # Mostrar resumen de datos existentes\n",
    "        print(\"\\nüìä RESUMEN DE DATOS EXISTENTES:\")\n",
    "        folder = \"datos_opta_parquet\"\n",
    "        parquet_files = {\n",
    "            'player_stats': 'player_stats.parquet',\n",
    "            'team_stats': 'team_stats.parquet', \n",
    "            'player_xg_stats': 'player_xg_stats.parquet',\n",
    "            'xg_events': 'xg_events.parquet',\n",
    "            'match_events': 'abp_events.parquet',\n",
    "            'team_officials': 'team_officials.parquet'\n",
    "        }\n",
    "        \n",
    "        result = {}\n",
    "        for data_type, filename in parquet_files.items():\n",
    "            filepath = f\"{folder}/{filename}\"\n",
    "            if os.path.exists(filepath):\n",
    "                df = pd.read_parquet(filepath)\n",
    "                result[data_type] = df\n",
    "                print(f\"   ‚úÖ {data_type}: {len(df)} filas\")\n",
    "            else:\n",
    "                result[data_type] = pd.DataFrame()\n",
    "                print(f\"   üìÑ {data_type}: archivo no existe\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    print(f\"\\nüìä Procesando {len(new_matches_df)} partidos nuevos...\")\n",
    "    match_ids = new_matches_df['Match ID'].tolist()\n",
    "    \n",
    "    # Procesar datos (solo partidos nuevos)\n",
    "    all_data = {\n",
    "        'player_stats': [],\n",
    "        'team_stats': [],\n",
    "        'player_xg_stats': [],\n",
    "        'xg_events': [],\n",
    "        'match_events': [],\n",
    "        'team_officials': []\n",
    "    }\n",
    "    \n",
    "    for i, match_id in enumerate(match_ids):\n",
    "        print(f\"‚öΩ Partido {i+1}/{len(match_ids)}: {match_id}\")\n",
    "        \n",
    "        # MA2 - Player Stats + Team Officials\n",
    "        player_stats_df, team_officials_df = process_matchPlayerStats_data(match_id)\n",
    "        if not player_stats_df.empty:\n",
    "            all_data['player_stats'].append(player_stats_df)\n",
    "        if not team_officials_df.empty:\n",
    "            all_data['team_officials'].append(team_officials_df)\n",
    "        \n",
    "        # MA2 - Team Stats\n",
    "        team_stats_df = process_matchTeamStats_data(match_id)\n",
    "        if not team_stats_df.empty:\n",
    "            all_data['team_stats'].append(team_stats_df)\n",
    "        \n",
    "        # MA3 - Match Events\n",
    "        match_events_df = process_match_events_data(match_id)\n",
    "        if not match_events_df.empty:\n",
    "            all_data['match_events'].append(match_events_df)\n",
    "        \n",
    "        # MA12 - Player xG Stats + Team Officials \n",
    "        player_xg_df, team_officials_xg_df = process_xG_matchPlayerStats_data(match_id)\n",
    "        if not player_xg_df.empty:\n",
    "            all_data['player_xg_stats'].append(player_xg_df)\n",
    "        if not team_officials_xg_df.empty:\n",
    "            all_data['team_officials'].append(team_officials_xg_df)\n",
    "        \n",
    "        # MA12 - xG Events\n",
    "        xg_events_df = process_xG_match_events(match_id)\n",
    "        if not xg_events_df.empty:\n",
    "            all_data['xg_events'].append(xg_events_df)\n",
    "        \n",
    "        if i < len(match_ids) - 1:\n",
    "            time.sleep(delay_seconds)\n",
    "    \n",
    "    # Combinar DataFrames de nuevos datos\n",
    "    new_data = {}\n",
    "    for data_type, df_list in all_data.items():\n",
    "        if df_list:\n",
    "            new_data[data_type] = pd.concat(df_list, ignore_index=True)\n",
    "            print(f\"‚úÖ {data_type} (nuevos): {len(new_data[data_type])} filas\")\n",
    "        else:\n",
    "            new_data[data_type] = pd.DataFrame()\n",
    "    \n",
    "    # Guardar (la funci√≥n save_to_parquet ya maneja la combinaci√≥n con datos existentes)\n",
    "    filename_prefix = f\"OPTA_Comp{config['competition_id']}_Stage{config['stage_id'][:8]}_Week{config['max_week']}\"\n",
    "    \n",
    "    print(f\"\\nüíæ Guardando datos nuevos y combinando con existentes...\")\n",
    "    save_to_parquet(new_data)\n",
    "    \n",
    "    # Cargar datos finales combinados para retornar\n",
    "    print(f\"\\nüìä CARGANDO DATOS FINALES COMBINADOS:\")\n",
    "    folder = \"datos_opta_parquet\"\n",
    "    parquet_files = {\n",
    "        'player_stats': 'player_stats.parquet',\n",
    "        'team_stats': 'team_stats.parquet', \n",
    "        'player_xg_stats': 'player_xg_stats.parquet',\n",
    "        'xg_events': 'xg_events.parquet',\n",
    "        'match_events': 'abp_events.parquet',\n",
    "        'team_officials': 'team_officials.parquet'\n",
    "    }\n",
    "    \n",
    "    final_result = {}\n",
    "    for data_type, filename in parquet_files.items():\n",
    "        filepath = f\"{folder}/{filename}\"\n",
    "        if os.path.exists(filepath):\n",
    "            df = pd.read_parquet(filepath)\n",
    "            final_result[data_type] = df\n",
    "            print(f\"   ‚úÖ {data_type}: {len(df)} filas totales\")\n",
    "        else:\n",
    "            final_result[data_type] = pd.DataFrame()\n",
    "    \n",
    "    print(f\"\\n‚úÖ Completado! Archivos actualizados con prefijo: {filename_prefix}\")\n",
    "    print(f\"üéâ Descarga incremental: {len(new_matches_df)} partidos nuevos procesados\")\n",
    "    \n",
    "    return final_result\n",
    "\n",
    "def quick_analysis(data):\n",
    "    \"\"\"An√°lisis r√°pido\"\"\"\n",
    "    print(\"\\nüìä AN√ÅLISIS R√ÅPIDO:\")\n",
    "    \n",
    "    for data_type, df in data.items():\n",
    "        if not df.empty:\n",
    "            print(f\"\\n{data_type}: {len(df)} filas\")\n",
    "            \n",
    "            if data_type == 'xg_events':\n",
    "                # Analizar eventos xG\n",
    "                xg_events = df[df['qualifier 321'].notna() & (df['qualifier 321'] != '0')]\n",
    "                if not xg_events.empty:\n",
    "                    print(f\"  üéØ Eventos con xG: {len(xg_events)}\")\n",
    "            \n",
    "            elif data_type == 'player_stats':\n",
    "                print(f\"  üë• Jugadores √∫nicos: {df['Player ID'].nunique()}\")\n",
    "                print(f\"  üìä Partidos √∫nicos: {df['Match ID'].nunique()}\")\n",
    "                print(f\"  üóìÔ∏è Stages √∫nicos: {df['Stage ID'].nunique()}\")\n",
    "            \n",
    "            elif data_type == 'team_stats':\n",
    "                print(f\"  üèÜ Equipos √∫nicos: {df['Team ID'].nunique()}\")\n",
    "                if 'Is Home' in df.columns:\n",
    "                    home_teams = df[df['Is Home'] == 'True']['Team Name'].nunique()\n",
    "                    away_teams = df[df['Is Away'] == 'True']['Team Name'].nunique()\n",
    "                    print(f\"  üè† Equipos locales: {home_teams}\")\n",
    "                    print(f\"  üöå Equipos visitantes: {away_teams}\")\n",
    "                    \n",
    "                    # Mostrar marcadores si est√°n disponibles\n",
    "                    if 'FT Home Score' in df.columns:\n",
    "                        matches_with_scores = df[df['FT Home Score'].notna()]\n",
    "                        if not matches_with_scores.empty:\n",
    "                            print(f\"  ‚öΩ Partidos con marcador final: {len(matches_with_scores)}\")\n",
    "\n",
    "def get_home_away_info(match_info, live_data):\n",
    "    \"\"\"Extrae informaci√≥n de home/away del partido\"\"\"\n",
    "    contestants = match_info.get('contestant', [])\n",
    "    match_details = live_data.get('matchDetails', {})\n",
    "    \n",
    "    # Crear mapeo de equipos\n",
    "    team_mapping = {}\n",
    "    home_team_id = None\n",
    "    away_team_id = None\n",
    "    \n",
    "    for contestant in contestants:\n",
    "        team_id = contestant.get('id')\n",
    "        team_name = contestant.get('name', 'N/A')  # ‚úÖ ESTA L√çNEA ES CORRECTA\n",
    "        position = contestant.get('position', '')\n",
    "        \n",
    "        team_mapping[team_id] = {\n",
    "            'name': team_name,\n",
    "            'position': position\n",
    "        }\n",
    "        \n",
    "        if position.lower() == 'home':\n",
    "            home_team_id = team_id\n",
    "        elif position.lower() == 'away':\n",
    "            away_team_id = team_id\n",
    "    \n",
    "    # Obtener marcadores si est√°n disponibles\n",
    "    scores = match_details.get('scores', {})\n",
    "    ht_scores = scores.get('ht', {})\n",
    "    ft_scores = scores.get('ft', {})\n",
    "    \n",
    "    return {\n",
    "        'home_team_id': home_team_id,\n",
    "        'away_team_id': away_team_id,\n",
    "        'team_mapping': team_mapping,\n",
    "        'ht_home': ht_scores.get('home', None),\n",
    "        'ht_away': ht_scores.get('away', None),\n",
    "        'ft_home': ft_scores.get('home', None),\n",
    "        'ft_away': ft_scores.get('away', None)\n",
    "    }\n",
    "\n",
    "def discover_stage_ids_for_competition(competition_id):\n",
    "    \"\"\"Descubre Stage IDs para una competici√≥n espec√≠fica\"\"\"\n",
    "    print(f\"üîç Descubriendo Stage IDs para competici√≥n {competition_id}...\")\n",
    "    \n",
    "    stages = get_available_stages(competition_id)\n",
    "    print(f\"üìä Stages encontrados:\")\n",
    "    for stage_id, stage_info in stages.items():\n",
    "        if isinstance(stage_info, dict):\n",
    "            print(f\"  '{stage_id}': '{stage_info.get('name', 'N/A')}'\")\n",
    "        else:\n",
    "            print(f\"  '{stage_id}': '{stage_info}'\")\n",
    "    \n",
    "    return stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9881456e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ OPTA API - EXTRACTOR CON SELECCI√ìN DE TEMPORADA\n",
      "üìä Feeds: MA2 (Stats), MA3 (Events), MA12 (xG)\n",
      "\n",
      "üí° STAGE ID CONOCIDO:\n",
      "   üá™üá∏ La Liga 2024-25: 4xu8dwf3cotp5qu0ddi50wkyc\n",
      "üéØ EXTRACCI√ìN OPTA - MA2, MA3 Y MA12 CON SELECCI√ìN DE TEMPORADA\n",
      "\n",
      "üá™üá∏ LA LIGA - SELECCIONA TEMPORADA:\n",
      "   üîÑ Intentando con MA1 b√°sico...\n",
      "  1: Temporada 2023/24 ‚úÖ\n",
      "  2: Temporada 2024/25 ‚úÖ\n",
      "  3: Temporada 2025/26 ‚úÖ\n",
      "\n",
      "‚úÖ Configuraci√≥n:\n",
      "   üèÜ Competici√≥n: 15\n",
      "   üóìÔ∏è Temporada: La Liga 2024/25\n",
      "   üìÖ Jornadas: 1-10\n",
      "   üìä Feeds: MA2 (Match Stats), MA3 (Events), MA12 (xG)\n",
      "üîç Revisando archivos existentes...\n",
      "   üìÑ player_stats.parquet: no existe\n",
      "   üìÑ team_stats.parquet: no existe\n",
      "   üìÑ player_xg_stats.parquet: no existe\n",
      "   üìÑ xg_events.parquet: no existe\n",
      "   üìÑ abp_events.parquet: no existe\n",
      "   üìÑ team_officials.parquet: no existe\n",
      "   üìÅ No se encontraron datos previos - descarga completa\n",
      "\n",
      "üîÑ Obteniendo partidos...\n",
      "üìÖ Jornada 1...\n",
      "   ‚úÖ Encontrados 10 partidos en jornada 1\n",
      "üìÖ Jornada 2...\n",
      "   ‚úÖ Encontrados 10 partidos en jornada 2\n",
      "üìÖ Jornada 3...\n",
      "   ‚úÖ Encontrados 10 partidos en jornada 3\n",
      "üìÖ Jornada 4...\n",
      "   ‚úÖ Encontrados 10 partidos en jornada 4\n",
      "üìÖ Jornada 5...\n",
      "   ‚úÖ Encontrados 10 partidos en jornada 5\n",
      "üìÖ Jornada 6...\n",
      "   ‚úÖ Encontrados 10 partidos en jornada 6\n",
      "üìÖ Jornada 7...\n",
      "   ‚úÖ Encontrados 10 partidos en jornada 7\n",
      "üìÖ Jornada 8...\n",
      "   ‚úÖ Encontrados 10 partidos en jornada 8\n",
      "üìÖ Jornada 9...\n",
      "   ‚úÖ Encontrados 10 partidos en jornada 9\n",
      "üìÖ Jornada 10...\n",
      "   ‚úÖ Encontrados 10 partidos en jornada 10\n",
      "\n",
      "üìä Total partidos encontrados: 100\n",
      "\n",
      "üîç Filtrando partidos nuevos...\n",
      "   üÜï Todos los partidos son nuevos: 100\n",
      "\n",
      "üìä Procesando 100 partidos nuevos...\n",
      "‚öΩ Partido 1/100: 5glmgn713wlnica0brb18c650\n",
      "‚öΩ Partido 2/100: 5j0zusmwyelfhjs2edw4ztfdg\n",
      "‚öΩ Partido 3/100: 5flq3r7vdtxfv2ysdhmhlxs7o\n",
      "‚öΩ Partido 4/100: 5hl3kbigpss3j000mn0oejg2c\n",
      "‚öΩ Partido 5/100: 5h3b0pzfw6ldoy2w08t39smj8\n",
      "‚öΩ Partido 6/100: 5ilutiy199xb72tzt92jl8ges\n",
      "‚öΩ Partido 7/100: 5g3vemb94j4xdrnwt6wkmsyz8\n",
      "‚öΩ Partido 8/100: 5i2tjytubfo8jgi6mockkrkt0\n",
      "‚öΩ Partido 9/100: 5f3ska55qwluoz1kkft477das\n",
      "‚öΩ Partido 10/100: 5ei8cjo15u5k6qgqims0rsutw\n",
      "‚öΩ Partido 11/100: 5jegs4j4ybvjcgdaghy7ilwk4\n",
      "‚öΩ Partido 12/100: 5le7pln28h10g7u3vlsspflzo\n",
      "‚öΩ Partido 13/100: 5lsd435qp9ov0369fxwxsdq8k\n",
      "‚öΩ Partido 14/100: 5kldlsgi64xxe5nym5szuok5w\n",
      "‚öΩ Partido 15/100: 5m5srxg0a0rsvjcthcv4qdxqs\n",
      "‚öΩ Partido 16/100: 5k75djtbbjl493cac58zuyqs4\n",
      "‚öΩ Partido 17/100: 5mj8s0rijkav768ck08cz6fbo\n",
      "‚öΩ Partido 18/100: 5mxpzicz2rwte364wph5ct3bo\n",
      "‚öΩ Partido 19/100: 5kzt2vp9lvxghav8iiertuplg\n",
      "‚öΩ Partido 20/100: 5jstvmxnddtgt2x7z9kyrx0yc\n",
      "‚öΩ Partido 21/100: 5ns4fg6y1hq3cufyms4pd1vdg\n",
      "‚öΩ Partido 22/100: 5ozboc3vkmy8gtsk7gxb7imms\n",
      "‚öΩ Partido 23/100: 5o6kqt43c2cjrkp0b6ufovvo4\n",
      "‚öΩ Partido 24/100: 5qxo256z1jw0dps23hd0k06qc\n",
      "‚öΩ Partido 25/100: 5q63q612ph6ma47d4rf69naj8\n",
      "‚öΩ Partido 26/100: 5qk8chtwtmvvpatkmcksfcutw\n",
      "‚öΩ Partido 27/100: 5nbu5gmdx5gm9b2wjsybtr76c\n",
      "‚öΩ Partido 28/100: 5pdlhap2xv8f1uannrtk1f4lw\n",
      "‚öΩ Partido 29/100: 5okyjoqk1187nzifkct2bqcr8\n",
      "‚öΩ Partido 30/100: 5prygp8gcta4ykggusdxqwys4\n",
      "‚öΩ Partido 31/100: 5u3wx1ukwc8ezs3iztiha7bx0\n",
      "‚öΩ Partido 32/100: 5s3xwqhpxe5lxs3fskk6vtr84\n",
      "‚öΩ Partido 33/100: 5ux5nsf6org4a8iugiyofzlec\n",
      "‚öΩ Partido 34/100: 5uiswh4s7uixm5suih5vyz2ms\n",
      "‚öΩ Partido 35/100: 5synj2tonhl9q7029mdt8p2qc\n",
      "‚öΩ Partido 36/100: 5td1p1s4tqjpjp87klzwu2rkk\n",
      "‚öΩ Partido 37/100: 5sicbm55qbgeecbcprwy97uac\n",
      "‚öΩ Partido 38/100: 5tqfezsv146ktc9c481m2lkpg\n",
      "‚öΩ Partido 39/100: 5rb6zpmugit67qx1oa0b3tz4k\n",
      "‚öΩ Partido 40/100: 5rpelvwkel423rwai2gfaekno\n",
      "‚öΩ Partido 41/100: 5y4lx9rzp0ow61yo13pi3nxuc\n",
      "‚öΩ Partido 42/100: 5vblcjrjoaquvkt23jpttrlec\n",
      "‚öΩ Partido 43/100: 5wxdb9o5eg7sffkn8m09r0qok\n",
      "‚öΩ Partido 44/100: 5xbnsmhknyjgljqluckg5ifx0\n",
      "‚öΩ Partido 45/100: 5w4b6ohqxt21h0vglnjgvpes4\n",
      "‚öΩ Partido 46/100: 5yklujtutkh5ksc5f5iojpdzo\n",
      "‚öΩ Partido 47/100: 5xq75nlg0hhutyqys6lqj0hzo\n",
      "‚öΩ Partido 48/100: 5yyc4zqwgchbo16kocdcq1ams\n",
      "‚öΩ Partido 49/100: 5wiwtn06uxlem9qm2mhnxggt0\n",
      "‚öΩ Partido 50/100: 5vpwbyi79lvl0ukif4cyygnpw\n",
      "‚öΩ Partido 51/100: 5zqhn00v48eye91tctbo1uo0k\n",
      "‚öΩ Partido 52/100: 60yfcq9jjwkz23gcvqpuifoyc\n",
      "‚öΩ Partido 53/100: 61cwhjuf2ktyf9a4amp57ieqc\n",
      "‚öΩ Partido 54/100: 5zc13oz3ip4z5wbqbhej6uhhw\n",
      "‚öΩ Partido 55/100: 604ya0n4fh6nijyxuxybr0is4\n",
      "‚öΩ Partido 56/100: 62ynouhnra4702bfgi3cuakus\n",
      "‚öΩ Partido 57/100: 61rjxg15ik34493xle4c72psk\n",
      "‚öΩ Partido 58/100: 62kw8d568qve1rhminzbmxn9w\n",
      "‚öΩ Partido 59/100: 626errdvn7ta3vncvipxpdtzo\n",
      "‚öΩ Partido 60/100: 60jqe1h7rodt2n113439gf40k\n",
      "‚öΩ Partido 61/100: 65s0nz9qa94kr4g9my3p7ynf8\n",
      "‚öΩ Partido 62/100: 666itf9ca5gc32h2l5wlo6zo4\n",
      "‚öΩ Partido 63/100: 64zsgl4deyxdr5rdpamwtlams\n",
      "‚öΩ Partido 64/100: 63caanmmwfogw1hbixp2zklqs\n",
      "‚öΩ Partido 65/100: 63syq47tm563i22egotcb7itw\n",
      "‚öΩ Partido 66/100: 66zosz3fqz2ztfu9it2muu42c\n",
      "‚öΩ Partido 67/100: 66l34ax3m29s58ud7hbv3bd3o\n",
      "‚öΩ Partido 68/100: 64lywndahglmvr118amfxkf10\n",
      "‚öΩ Partido 69/100: 65dekeom0wbecv9pu2vfb9kb8\n",
      "‚öΩ Partido 70/100: 647jn50wp2vojesyn36x66nf8\n",
      "‚öΩ Partido 71/100: 69v1396td9466vft0tuygcd90\n",
      "‚öΩ Partido 72/100: 67t6jdk03argdkp4enrhycqac\n",
      "‚öΩ Partido 73/100: 6b1o8xruzdij3xnwprnkwt05w\n",
      "‚öΩ Partido 74/100: 67elmttf59akqb6h72l7fqqz8\n",
      "‚öΩ Partido 75/100: 687puky17rzj95b7f9rqb1rtg\n",
      "‚öΩ Partido 76/100: 690iee00hs40h0o94hak47tp0\n",
      "‚öΩ Partido 77/100: 68m2m1s5dol5di2vl19e1hd78\n",
      "‚öΩ Partido 78/100: 6ao078l4kyhkgamhkopljt89g\n",
      "‚öΩ Partido 79/100: 6a9fqe2av4fcdm83qdsuvqrro\n",
      "‚öΩ Partido 80/100: 69gpwcr00zri26svtn0oaoduc\n",
      "‚öΩ Partido 81/100: 6dtjx87yffxl5ac75q3k13pqs\n",
      "‚öΩ Partido 82/100: 6e8fu3jiqoblrt70tfpycctuc\n",
      "‚öΩ Partido 83/100: 6c8p4cgbqywptvo6lilt2mnf8\n",
      "‚öΩ Partido 84/100: 6dejybh88d2bz7rbo64nxde6s\n",
      "‚öΩ Partido 85/100: 6bu6tnf33gay36zm1d6p61wr8\n",
      "‚öΩ Partido 86/100: 6f40b8phg3ut4rbh119krjwgk\n",
      "‚öΩ Partido 87/100: 6epfq0i6hy5rpdobekarp5st0\n",
      "‚öΩ Partido 88/100: 6bfl7c5wl3huc70e8fbok8ys4\n",
      "‚öΩ Partido 89/100: 6d0u0xeee4wz6ojhbyh2r6yac\n",
      "‚öΩ Partido 90/100: 6cn9zts9vzu0cfy0ms2pbf1uc\n",
      "‚öΩ Partido 91/100: 6irfxmrjbaan5caqwab8xq9zo\n",
      "‚öΩ Partido 92/100: 6fxech6nwatkx9ve4yusp3uhg\n",
      "‚öΩ Partido 93/100: 6icvpmsvyijojghn1uhr94kk4\n",
      "‚öΩ Partido 94/100: 6fis5s5i2e7uv1z8wzcrlnk0k\n",
      "‚öΩ Partido 95/100: 6h4opdcr03yxpmu6u4lcmqln8\n",
      "‚öΩ Partido 96/100: 6gbsyrjq2pwe4heho3hx6pclw\n",
      "‚öΩ Partido 97/100: 6gq5zi3dzxmlg34bc0p1qh5w4\n",
      "‚öΩ Partido 98/100: 6hycbbluudc6jssb3mesju7tg\n",
      "‚öΩ Partido 99/100: 6j53txcxd3d5xymq7py5kykus\n",
      "‚öΩ Partido 100/100: 6hjbwnq8ofmw5i84s9la32p04\n",
      "‚úÖ player_stats (nuevos): 4474 filas\n",
      "‚úÖ team_stats (nuevos): 200 filas\n",
      "‚úÖ player_xg_stats (nuevos): 4474 filas\n",
      "‚úÖ xg_events (nuevos): 2420 filas\n",
      "‚úÖ match_events (nuevos): 168611 filas\n",
      "‚úÖ team_officials (nuevos): 400 filas\n",
      "\n",
      "üíæ Guardando datos nuevos y combinando con existentes...\n",
      "üîÑ Procesando player_stats...\n",
      "   üìù Limpiando tipos de datos...\n",
      "üíæ Creado: datos_opta_parquet/player_stats.parquet (4474 filas)\n",
      "   ‚úÖ player_stats guardado exitosamente\n",
      "üîÑ Procesando team_stats...\n",
      "   üìù Limpiando tipos de datos...\n",
      "üíæ Creado: datos_opta_parquet/team_stats.parquet (200 filas)\n",
      "   ‚úÖ team_stats guardado exitosamente\n",
      "üîÑ Procesando player_xg_stats...\n",
      "   üìù Limpiando tipos de datos...\n",
      "üíæ Creado: datos_opta_parquet/player_xg_stats.parquet (4474 filas)\n",
      "   ‚úÖ player_xg_stats guardado exitosamente\n",
      "üîÑ Procesando xg_events...\n",
      "   üìù Limpiando tipos de datos...\n",
      "üíæ Creado: datos_opta_parquet/xg_events.parquet (2420 filas)\n",
      "   ‚úÖ xg_events guardado exitosamente\n",
      "üîÑ Procesando match_events...\n",
      "   üìù Limpiando tipos de datos...\n",
      "üíæ Creado: datos_opta_parquet/abp_events.parquet (168611 filas)\n",
      "   ‚úÖ match_events guardado exitosamente\n",
      "üîÑ Procesando team_officials...\n",
      "   üìù Limpiando tipos de datos...\n",
      "üíæ Creado: datos_opta_parquet/team_officials.parquet (400 filas)\n",
      "   ‚úÖ team_officials guardado exitosamente\n",
      "\n",
      "üìä CARGANDO DATOS FINALES COMBINADOS:\n",
      "   ‚úÖ player_stats: 4474 filas totales\n",
      "   ‚úÖ team_stats: 200 filas totales\n",
      "   ‚úÖ player_xg_stats: 4474 filas totales\n",
      "   ‚úÖ xg_events: 2420 filas totales\n",
      "   ‚úÖ match_events: 168611 filas totales\n",
      "   ‚úÖ team_officials: 400 filas totales\n",
      "\n",
      "‚úÖ Completado! Archivos actualizados con prefijo: OPTA_Comp15_Stage4xu8dwf3_Week10\n",
      "üéâ Descarga incremental: 100 partidos nuevos procesados\n",
      "\n",
      "üìä AN√ÅLISIS R√ÅPIDO:\n",
      "\n",
      "player_stats: 4474 filas\n",
      "  üë• Jugadores √∫nicos: 589\n",
      "  üìä Partidos √∫nicos: 100\n",
      "  üóìÔ∏è Stages √∫nicos: 1\n",
      "\n",
      "team_stats: 200 filas\n",
      "  üèÜ Equipos √∫nicos: 20\n",
      "  üè† Equipos locales: 20\n",
      "  üöå Equipos visitantes: 20\n",
      "  ‚öΩ Partidos con marcador final: 200\n",
      "\n",
      "player_xg_stats: 4474 filas\n",
      "\n",
      "xg_events: 2420 filas\n",
      "  üéØ Eventos con xG: 2409\n",
      "\n",
      "match_events: 168611 filas\n",
      "\n",
      "team_officials: 400 filas\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# EJECUCI√ìN\n",
    "# ====================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üéØ OPTA API - EXTRACTOR CON SELECCI√ìN DE TEMPORADA\")\n",
    "    print(\"üìä Feeds: MA2 (Stats), MA3 (Events), MA12 (xG)\")\n",
    "    \n",
    "    print(f\"\\nüí° STAGE ID CONOCIDO:\")\n",
    "    print(f\"   üá™üá∏ La Liga 2024-25: 4xu8dwf3cotp5qu0ddi50wkyc\")\n",
    "    \n",
    "    # Ejecutar extracci√≥n directa\n",
    "    data = main_interactive()\n",
    "    if data:\n",
    "        quick_analysis(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
